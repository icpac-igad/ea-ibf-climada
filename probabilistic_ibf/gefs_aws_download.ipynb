{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AWS S3 configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996cbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "import ntpath\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pygrib\n",
    "import configparser\n",
    "\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/.aws/credentials')\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3', aws_access_key_id=config['default']['aws_access_key_id'],aws_secret_access_key=config['default']['aws_secret_access_key'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051349f7",
   "metadata": {},
   "source": [
    "## GRIB binary selection and download single variable functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fe156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_leaf(path):\n",
    "    \"\"\"\n",
    "    Get the name of a file without any extension from given path\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : file full path with extension\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "       filename in the path without extension\n",
    "\n",
    "    \"\"\"\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "\n",
    "\n",
    "def get_byte_range(lines,searchstring_list):\n",
    "    byte_range_list=[]\n",
    "    for searchstring in searchstring_list:\n",
    "        expr = re.compile(searchstring)\n",
    "        byte_ranges = {}\n",
    "        for n, line in enumerate(lines, start=1):\n",
    "            # n is the line number (starting from 1) so that when we call for \n",
    "            # `lines[n]` it will give us the next line. (Clear as mud??)\n",
    "    \n",
    "            # Use the compiled regular expression to search the line\n",
    "            if expr.search(line):   \n",
    "                # aka, if the line contains the string we are looking for...\n",
    "    \n",
    "                # Get the beginning byte in the line we found\n",
    "                parts = line.split(':')\n",
    "                rangestart = int(parts[1])\n",
    "    \n",
    "                # Get the beginning byte in the next line...\n",
    "                if n+1 < len(lines):\n",
    "                    # ...if there is a next line\n",
    "                    parts = lines[n].split(':')\n",
    "                    rangeend = int(parts[1])\n",
    "                else:\n",
    "                    # ...if there isn't a next line, then go to the end of the file.\n",
    "                    rangeend = ''\n",
    "    \n",
    "                # Store the byte-range string in our dictionary, \n",
    "                # and keep the line information too so we can refer back to it.\n",
    "                byte_ranges['start_byte']=rangestart\n",
    "                byte_ranges['end_byte']=rangeend\n",
    "                byte_ranges['parse_line'] = line\n",
    "                byte_range_list.append(byte_ranges)\n",
    "    if len(byte_range_list) ==2:\n",
    "        pbyte_range={}\n",
    "        pbyte_range['start_byte']=byte_range_list[0]['start_byte']\n",
    "        pbyte_range['end_byte']=byte_range_list[1]['end_byte']\n",
    "        pbyte_range['parse_line'] = byte_range_list[1]['parse_line']\n",
    "    else:\n",
    "        pbyte_range=byte_range_list[0]\n",
    "    return pbyte_range\n",
    "            \n",
    "\n",
    "def s3botodownloadfile(s3keylocation, bucket,localfolder):\n",
    "    \"\"\"\n",
    "    Download file in S3\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3keylocation : key location in s3 bucket\n",
    "    bucket : s3 bucket with target contents\n",
    "    localfolder : folder path in local to download the file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    filename=path_leaf(s3keylocation)\n",
    "    #filename=configz.date+'_pfz_gen_logs.txt' \n",
    "    s3_client.download_file(bucket,s3keylocation, '%s/%s' % (localfolder,filename))\n",
    "    download_filepath=localfolder+filename\n",
    "    return download_filepath, filename    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def s3_gfs_download(params):\n",
    "    s3keylocation=f'gefs.{params.startdate}/{params.run}/atmos/pgrb2sp25/gep{params.ensmem}.t{params.run}z.pgrb2s.0p25.f{params.timestep}'\n",
    "    s3keylocation_idx=f'{s3keylocation}.idx'\n",
    "    print(s3keylocation)\n",
    "    download_filepath, filename=s3botodownloadfile(s3keylocation_idx, params.awsbucketname,params.localfolder)\n",
    "    with open(download_filepath) as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "        \n",
    "    # Search \n",
    "    if isinstance(params.searchString, list):\n",
    "        searchstring_list=params.searchString\n",
    "        try:\n",
    "            byte_ranges=get_byte_range(lines,searchstring_list)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    else:\n",
    "        searchstring_list=[params.searchString]\n",
    "        try:\n",
    "            byte_ranges=get_byte_range(lines,searchstring_list)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    gribfilename=f'gep{params.ensmem}.t{params.run}z.pgrb2s.0p25.f{params.timestep}'\n",
    "    print(gribfilename)\n",
    "    try:\n",
    "        obj = s3_client.get_object(\n",
    "            Bucket=params.awsbucketname,\n",
    "            Key=s3keylocation,\n",
    "            Range='bytes={}-{}'.format(byte_ranges['start_byte'], byte_ranges['end_byte']))\n",
    "        with open(params.localfolder+gribfilename, 'wb') as f:\n",
    "            for chunk in obj['Body'].iter_chunks(chunk_size=4096):\n",
    "                f.write(chunk)\n",
    "        return gribfilename\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2423c85",
   "metadata": {},
   "source": [
    "## applying the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "hourlist=np.arange(3,243,3)\n",
    "member_list=np.arange(1,22,1)\n",
    "\n",
    "gfs_timestamp_list=[str(i).zfill(3) for i in hourlist]\n",
    "gefs_member_list=[str(i).zfill(2) for i in member_list]\n",
    "\n",
    "\n",
    "def foldercreator(path):\n",
    "   \"\"\"\n",
    "    creates a folder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : folder path\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    creates a folder\n",
    "    \"\"\"\n",
    "   if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "        \n",
    "class bin_create_params:\n",
    "    startdate='20220915'   \n",
    "    run='18'\n",
    "    time='2016-04-30T06:00:00.000Z'\n",
    "    folderpath='/home/hazard_data_gefs/2022082906_apcp/'\n",
    "    localfolder=folderpath\n",
    "    #timestep='006'\n",
    "    short_name='tmp'\n",
    "    awsbucketname='noaa-gefs-pds'\n",
    "    test_implmentation=0\n",
    "    searchString='APCP:surface:'\n",
    "    #searchString='TMP:2 m above ground'\n",
    "    ensmem='01'\n",
    "    \n",
    "params=bin_create_params()\n",
    "\n",
    "        \n",
    "\n",
    "for gefs_member  in gefs_member_list:\n",
    "    gefs_path=f'/home/hazard_data_gefs/{params.startdate}{params.run}/'\n",
    "    foldercreator(gefs_path)\n",
    "    gefs_member_path=f'{gefs_path}{gefs_member}/'\n",
    "    foldercreator(gefs_member_path)\n",
    "    for gfs_time in gfs_timestamp_list:\n",
    "        params.timestep=gfs_time\n",
    "        params.ensmem=gefs_member\n",
    "        params.folderpath=gefs_member_path\n",
    "        params.localfolder=gefs_member_path\n",
    "        s3_gfs_download(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
