{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to download files for east africa\n",
    "\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/10d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/113_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/141_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/143_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/15d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/161_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/163_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/165_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/167_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/169_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/16b_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/16d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/16f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/171_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/173_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/175_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/177_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/179_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/17b_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/17d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/17f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/181_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/183_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/185_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/189_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/18f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/191_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/199_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/19b_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/19d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/19f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3d5_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3d7_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3d9_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3db_buildings.csv.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/ea_5x5_grid.shp')\n",
    "\n",
    "bdb=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/3d5_buildings.csv.gz')\n",
    "\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n",
    "db = gbdb.sjoin(grid_db, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import gc\n",
    "import dask_geopandas\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "gzfiles=glob.glob('/home/data_folder/points_s2_level_4_gzip/*.csv.gz')\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/ea_5x5_grid.shp')\n",
    "\n",
    "# for gzfl in gzfiles:\n",
    "#     print(gzfl)\n",
    "#     bdb=pd.read_csv(gzfl)\n",
    "#     gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "#     dgdf = dask_geopandas.from_geopandas(gbdb, npartitions=4)\n",
    "#     db = dgdf.sjoin(grid_db, how=\"left\")\n",
    "#     db.drop(columns=['geometry', 'index_right','sno'], inplace=True)\n",
    "#     db.fillna('out_of_ea', inplace=True)\n",
    "#     dem_db=db.drop_duplicates('dem_name')\n",
    "#     dem_name_list=dem_db['dem_name'].tolist()\n",
    "#     dem_name_list=[i for i in dem_name_list if not i in 'out_of_ea']\n",
    "#     outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "#     del [[bdb,gbdb,dem_db]]\n",
    "#     gc.collect()\n",
    "#     bdb=pd.DataFrame()\n",
    "#     gbdb=pd.DataFrame()\n",
    "#     dem_db=pd.DataFrame()\n",
    "#     for dem_name in dem_name_list:\n",
    "#         db1=db[db['dem_name']==dem_name]\n",
    "#         db1.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter/{dem_name}_{outputname}.csv.gz', compression='gzip')\n",
    "#         del [[db1]]\n",
    "#         gc.collect()\n",
    "#         db1=pd.DataFrame()\n",
    "\n",
    "\n",
    "# for gzfl in gzfiles[8:]:\n",
    "#     print(gzfl)\n",
    "#     #bdb=pd.read_csv(gzfl)\n",
    "#     do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "#     bdb=do_dask_compute0.compute()\n",
    "#     gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "#     dgdf = dask_geopandas.from_geopandas(gbdb, npartitions=4)\n",
    "#     do_dask_compute = dgdf.sjoin(grid_db, how=\"inner\")\n",
    "#     db = do_dask_compute.compute()\n",
    "#     print(db.info())\n",
    "#     if db.empty:\n",
    "#         pass\n",
    "#     else:\n",
    "#         db.drop(columns=['geometry', 'index_right','sno'], inplace=True)\n",
    "#         dem_db=db.drop_duplicates('dem_name')\n",
    "#         print(dem_db)\n",
    "#         dem_name_list=dem_db['dem_name'].tolist()\n",
    "#         outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "#         del [[bdb,gbdb,dem_db]]\n",
    "#         gc.collect()\n",
    "#         bdb=pd.DataFrame()\n",
    "#         gbdb=pd.DataFrame()\n",
    "#         dem_db=pd.DataFrame()\n",
    "#         print('###########')\n",
    "#         for dem_name in dem_name_list:\n",
    "#             print(dem_name)\n",
    "#             print(db.info())\n",
    "#             db1=db[db['dem_name']==dem_name]\n",
    "#             db1.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter/{dem_name}_{outputname}.csv.gz', compression='gzip')\n",
    "#     del [[db1,db]]\n",
    "#     gc.collect()\n",
    "#     db1=pd.DataFrame()\n",
    "#     db=pd.DataFrame()\n",
    "\n",
    "\n",
    "# for gzfl in gzfiles:\n",
    "#     print(gzfl)\n",
    "#     #bdb=pd.read_csv(gzfl)\n",
    "#     do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "#     bdb=do_dask_compute0.compute()\n",
    "#     outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "#     for idx, row in grid_db.iterrows():\n",
    "#         min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "#         bdb = bdb.query(f'{min_long} < longitude < {max_long}')\n",
    "#         bdb = bdb.query(f'{min_lat} < latitude < {max_lat}')\n",
    "#         if not bdb.empty:\n",
    "#             print(bdb.info())\n",
    "#             bdb['dem_name']=row['dem_name']\n",
    "#             dem_name=row['dem_name']\n",
    "#             bdb.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter/{dem_name}_{outputname}.csv.gz', compression='gzip',index=False)\n",
    "#     gc.collect()\n",
    "#     del [[bdb]]\n",
    "#     bdb=pd.DataFrame()\n",
    "\n",
    "\n",
    "for gzfl in gzfiles:\n",
    "    print(gzfl)\n",
    "    #bdb=pd.read_csv(gzfl)\n",
    "    do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "    bdb=do_dask_compute0.compute()\n",
    "    outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "    for idx, row in grid_db.iterrows():\n",
    "        min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "        bdb1=bdb.loc[(bdb['longitude'] >=min_long ) & (bdb['longitude'] <= max_long)]\n",
    "        bdb2=bdb1.loc[(bdb1['latitude'] >=min_lat ) & (bdb1['latitude'] <= max_lat)]\n",
    "        if not bdb2.empty:\n",
    "            print(bdb2.info())\n",
    "            bdb2['dem_name']=row['dem_name']\n",
    "            dem_name=row['dem_name']\n",
    "            bdb2.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/{dem_name}_{outputname}.csv.gz', compression='gzip',index=False)\n",
    "            del [[bdb1,bdb2]]\n",
    "    gc.collect()\n",
    "    del [[bdb]]\n",
    "    bdb=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae79652",
   "metadata": {},
   "source": [
    "## replicate rtree method for building points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792a817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5446d516",
   "metadata": {},
   "source": [
    "## do 1km intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import geopandas as gp\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd081a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')\n",
    "# dgdf = dask_geopandas.from_geopandas(gbdb, npartitions=4)\n",
    "# do_dask_compute = dgdf.sjoin(grid_db, how=\"inner\")\n",
    "# db = do_dask_compute.compute()\n",
    "\n",
    "sindex = gbdb.sindex\n",
    "# possible_matches_index = list(sindex.intersection(geometry.bounds))\n",
    "# possible_matches = gdf_nodes.iloc[possible_matches_index]\n",
    "# precise_matches = possible_matches[possible_matches.intersects(geometry)]\n",
    "\n",
    "points_within_geometry = pd.DataFrame()\n",
    "\n",
    "for idx,row in grid_db.iterrows():\n",
    "    # buffer by the <1 micron dist to account for any space lost in the quadrat cutting\n",
    "    # otherwise may miss point(s) that lay directly on quadrat line\n",
    "    poly = row['geometry'].buffer(1e-14).buffer(0)\n",
    "\n",
    "    # find approximate matches with r-tree, then precise matches from those approximate ones\n",
    "    possible_matches_index = list(sindex.intersection(poly.bounds))\n",
    "    possible_matches = gbdb.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.intersects(poly)]\n",
    "    points_within_geometry = points_within_geometry.append(precise_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210463e3",
   "metadata": {},
   "source": [
    "## Following the road network inteserction method for point as well\n",
    "1. For OSM road network it took 10 hours for all the 5x5 grid\n",
    "2. expecting similar operation for building points as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf55f6c",
   "metadata": {},
   "source": [
    "## test routine \n",
    "1. the csv.gz file has to be converted into shape file first \n",
    "2. then do the usual operation of point in polygon following road network intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import geopandas as gp\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e045_dem_3d5_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n",
    "#gbdb.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/n00e030_dem_177_buildings.shp',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10991b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdb=[]\n",
    "gbdb.drop(columns=['latitude', 'longitude','area_in_meters','confidence','full_plus_code','dem_name'], inplace=True)\n",
    "gbdb.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/n00e045_dem_3d5_buildings.shp',index=False)\n",
    "#gbdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "millnames = ['',' Thousand',' Million',' Billion',' Trillion']\n",
    "\n",
    "def millify(n):\n",
    "    n = float(n)\n",
    "    millidx = max(0,min(len(millnames)-1,\n",
    "                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))\n",
    "    return '{:.0f}{}'.format(n / 10**(3 * millidx), millnames[millidx])\n",
    "\n",
    "millify(len(gbdb.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape, mapping\n",
    "import rtree\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import ntpath\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "def intersect(buidling_shp_layer,boundary_shp,grid_name,output_shp,dummy_schema):\n",
    "    with fiona.open(boundary_shp, 'r') as boundary_shp_layer:\n",
    "        # We copy schema and add the  new property for the new resulting shp\n",
    "        schema = dummy_schema\n",
    "        schema['properties']['gno'] = 'int:10'\n",
    "        schema['properties']['latitude'] = 'int:10'\n",
    "        schema['properties']['longitude'] = 'int:10'\n",
    "        schema['properties']['area_in_meters'] = 'int:10'\n",
    "        schema['properties']['confidence'] = 'int:10'\n",
    "        schema['properties']['full_plus_code'] = 'str'\n",
    "        schema['properties']['dem_name'] = 'str'\n",
    "        # We open a first empty shp to write new content from both others shp\n",
    "        with fiona.open(output_shp, 'w', 'ESRI Shapefile', schema) as output_shp_layer:\n",
    "            index = rtree.index.Index()\n",
    "            for feat1 in boundary_shp_layer:\n",
    "                fid = int(feat1['id'])\n",
    "                geom1 = shape(feat1['geometry'])\n",
    "                index.insert(fid, geom1.bounds)\n",
    "            for feat2 in buidling_shp_layer:\n",
    "                geom2 = shape(feat2['geometry'])\n",
    "                for fid in list(index.intersection(geom2.bounds)):\n",
    "                    if fid != int(feat2['id']):\n",
    "                        feat1 = boundary_shp_layer[fid]\n",
    "                        geom1 = shape(feat1['geometry'])\n",
    "                        if geom1.intersects(geom2):\n",
    "                            # We take attributes from ctSHP\n",
    "                            props = feat2['properties']\n",
    "                            # Then append the uid attribute we want from the other shp\n",
    "                            #props['code'] = grid_name\n",
    "                            geom3=geom1.intersection(geom2)\n",
    "                            if geom3.geom_type=='GeometryCollection':\n",
    "                                print(\"empty geometry\")\n",
    "                            #elif geom3.geom_type=='Point':\n",
    "                            #    print(props)\n",
    "                            else:\n",
    "                                props['gno'] = feat1['properties']['Maille']\n",
    "                                output_shp_layer.write({\n",
    "                                  'properties': props,\n",
    "                                  'geometry': mapping(geom1.intersection(geom2))\n",
    "                                })\n",
    "\n",
    "buidling_shp_layer=pointpd   \n",
    "\n",
    "boundary_shp=f'/home/data_folder/osm_data/5x5_1km_grids_ea/n00e045_dem.shp'\n",
    "\n",
    "grid_name='km_intersection'\n",
    "\n",
    "output_shp='/home/data_folder/points_s2_level_4_gzip/km_intersection/test1.shp'\n",
    "intersect(buidling_shp_layer,boundary_shp,grid_name,output_shp,dummy_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_shp  = '/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/n00e045_dem_3d5_buildings.shp'\n",
    "road_shp_layer= fiona.open(road_shp, 'r')\n",
    "\n",
    "dummy_schema = road_shp_layer.schema.copy()\n",
    "\n",
    "dummy_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ef25f",
   "metadata": {},
   "source": [
    "## convert geopandsa into fiona collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8177ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import geopandas as gp\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e045_dem_3d5_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n",
    "#dd=df.loc[:, df.columns != 'geometry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f323b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def extract_point_coords(index,row,rdd):\n",
    "    geom=row['geometry'].coords[:][0]\n",
    "    res = zip(row[rdd].index,row[rdd])\n",
    "    return {'geometry':{'coordinates': geom,'type': 'Point'},\n",
    "             'id':index,\n",
    "             'properties':OrderedDict(res),\n",
    "            'type': 'Feature'}\n",
    "  \n",
    "\n",
    "rdd=gbdb.columns\n",
    "  \n",
    "pointpd=[]\n",
    "for index, row in gbdb[0:1000].iterrows():\n",
    "    ee=extract_point_coords(index,row,rdd)\n",
    "    pointpd.append(ee)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6584fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom2 = shape(pointpd[0]['geometry'])\n",
    "pointpd[0]['geometry'],geom2.bounds\n",
    "#geom2.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=gp.read_file('/home/data_folder/points_s2_level_4_gzip/km_intersection/test.shp')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=gbdb[0:1000]\n",
    "aa.to_file('/home/data_folder/points_s2_level_4_gzip/km_intersection/points.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4880b1",
   "metadata": {},
   "source": [
    "## Using non gis filtering method for 1km grid as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2752c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cont_bc=[]\n",
    "for idx, row in grid_db.iterrows():\n",
    "    min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "    bdb1=bdb.loc[(bdb['longitude'] >=min_long ) & (bdb['longitude'] <= max_long)]\n",
    "    bdb2=bdb1.loc[(bdb1['latitude'] >=min_lat ) & (bdb1['latitude'] <= max_lat)]\n",
    "    if not bdb2.empty:\n",
    "        build_count=len(bdb2.index)\n",
    "    else:\n",
    "        build_count=0\n",
    "    cont_bc.append(build_count)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b950e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inpoly import inpoly2\n",
    "import numpy as np\n",
    "    \n",
    "xmin, xmax, ymin, ymax = 0, 1, 0, 1\n",
    "x0, y0, x1, y1 = 0.5, 0.5, 0, 1\n",
    "\n",
    "#define any n-sided polygon\n",
    "p = np.array([[xmin, ymin],\n",
    "              [xmax, ymin],\n",
    "              [xmax, ymax],\n",
    "              [xmin, ymax],\n",
    "              [xmin, ymin]])\n",
    "\n",
    "#define some coords\n",
    "coords = np.array([[x0, y0],\n",
    "                   [x1, y1]])\n",
    "\n",
    "#get boolean mask for points if in or on polygon perimeter\n",
    "isin, ison = inpoly2(coords, p)\n",
    "\n",
    "https://stackoverflow.com/questions/36399381/whats-the-fastest-way-of-checking-if-a-point-is-inside-a-polygon-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1285b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## keranl getting killed if th following file is read in pandas, so using dask\n",
    "\n",
    "#import pandas as pd\n",
    "#db=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/165_buildings.csv.gz')\n",
    "\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('/home/data_folder/points_s2_level_4_gzip/165_buildings.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946812c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dgdf.sjoin(grid_db, how=\"inner\")\n",
    "db1 = db.compute()\n",
    "#db.drop(columns=['geometry', 'index_right','sno'])\n",
    "#db.fillna('out_of_ea')\n",
    "#dem_db=db.drop_duplicates('dem_name')\n",
    "#dem_name_list=dem_db['dem_name'].tolist()\n",
    "#dem_db\n",
    "db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = gbdb.sjoin(grid_db, how=\"left\")\n",
    "dba=db.dropna()\n",
    "dba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5332ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_name_list=['n05e020_dem','out_of_ea', 'n10e020_dem']\n",
    "\n",
    "[i for i in dem_name_list if not i in 'out_of_ea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c348ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_db=db.drop_duplicates('dem_name')\n",
    "dem_db.fillna('out_of_ea', inplace=True)\n",
    "dem_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for idx, row in grd_db.iterrows():\n",
    "    min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "    for gzfl in gzfiles:\n",
    "        bdb=pd.read_csv(gzfl)\n",
    "        bdb1=bdb.loc[(bdb['latitude'] >=min_lat ) & (bdb['latitude'] <= max_lat)]\n",
    "# bdb.loc[(bdb['longitude'] >=min_lon ) & (bdb['longitude'] <= max_lon)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b9be3",
   "metadata": {},
   "source": [
    "## make all 1km grid into single shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/ea_5x5_grid.shp')\n",
    "\n",
    "\n",
    "db_cont=[]\n",
    "for idx,row in grid_db.iterrows():\n",
    "    grid_name=row['dem_name']\n",
    "    db=gp.read_file(f'/home/data_folder/osm_data/5x5_1km_grids_ea/{grid_name}.shp')\n",
    "    db_cont.append(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "db=pd.concat(db_cont)\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db1=gp.GeoDataFrame(db)\n",
    "db1.to_file('/home/data_folder/osm_data/ea_5x5_1km_grids.shp',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_long,min_lat,max_long,max_lat=grid_db['geometry'][0].bounds\n",
    "\n",
    "# bdb.loc[(bdb['latitude'] >=min_lat ) & (bdb['latitude'] <= max_lat)]\n",
    "# bdb.loc[(bdb['longitude'] >=min_lon ) & (bdb['longitude'] <= max_lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_long,min_lat,max_long,max_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66967ce7",
   "metadata": {},
   "source": [
    "# Using KDTRee method with apply method \n",
    "\n",
    "https://stackoverflow.com/questions/27523982/how-to-find-set-of-points-in-x-y-grid-using-kdtree-query-ball-tree\n",
    "\n",
    "https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "\n",
    "1. earlier methods are inefficient in completing the grid intersection\n",
    "2. so using kdtree and apply method for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3621d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [2 2]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "pts = np.array([(1, 1), (2, 1), (3, 1), (4, 1), (1, 2), (2, 2), (3, 2), (4, 2), (1, 3), (2, 3), (3, 3), (4, 3), (1, 4), (2, 4), (3, 4), (4, 4)])\n",
    "\n",
    "T = KDTree(pts)\n",
    "idx = T.query_ball_point([1,1],r=2)\n",
    "print(pts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b247b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "#gd_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')\n",
    "\n",
    "bd_pt=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz')\n",
    "\n",
    "bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae52c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/3244142547.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bd_pt1.drop(columns=['lat_long'], inplace=True)\n",
      "/tmp/ipykernel_2584/3244142547.py:10: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gbd_pt.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/test.shp')\n"
     ]
    }
   ],
   "source": [
    "#bdpt_list=bd_pt['lat_long'].tolist()\n",
    "\n",
    "bd_pt1=bd_pt[0:1000]\n",
    "\n",
    "# \n",
    "\n",
    "bd_pt1.drop(columns=['lat_long'], inplace=True)\n",
    "gbd_pt=gp.GeoDataFrame(bd_pt1,geometry=gp.points_from_xy(bd_pt1.longitude,bd_pt1.latitude))\n",
    "\n",
    "#gbd_pt.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/test.shp')\n",
    "#bd_pt1\n",
    "gbd_pt['lat_long']=gbd_pt[['latitude','longitude']].apply(tuple,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a131d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18 Million'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "millnames = ['',' Thousand',' Million',' Billion',' Trillion']\n",
    "\n",
    "def millify(n):\n",
    "    n = float(n)\n",
    "    millidx = max(0,min(len(millnames)-1,\n",
    "                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))\n",
    "    return '{:.0f}{}'.format(n / 10**(3 * millidx), millnames[millidx])\n",
    "\n",
    "millify(len(bd_pt.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cfad0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "fe=len(bd_pt)/16\n",
    "db=bd_pt[0:int(fe)]\n",
    "\n",
    "bdpt_list0=db['lat_long'].tolist()\n",
    "bdpt_list=np.array(bdpt_list0)\n",
    "kdt_bdpt_list = KDTree(bdpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138a8d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1135259"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bdpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f16f685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 Million'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millify(len(db.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3060865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017192232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import objsize\n",
    "objsize.get_deep_size(bdpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf69fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "    pts_in_poly_roundbuffer=building_points[idx]\n",
    "    #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    #db.columns=['lat','lon']\n",
    "    #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "    return idx\n",
    "    \n",
    "\n",
    "    \n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')    \n",
    "\n",
    "\n",
    "grid_db['x']=grid_db.centroid.x\n",
    "grid_db['y']=grid_db.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c171f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gn', 'Maille', 'Maille_Y', 'Maille_X', 'geometry', 'x', 'y'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e371d12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14caf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "    #pts_in_poly_roundbuffer=building_points[idx]\n",
    "    #idx=[grid_lat,grid_lon]\n",
    "    #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    #db.columns=['lat','lon']\n",
    "    #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "    return idx\n",
    "\n",
    "\n",
    "# def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "#     '''\n",
    "#     Notes\n",
    "#     '''\n",
    "#     #idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "#     #pts_in_poly_roundbuffer=building_points[idx]\n",
    "#     idx=[grid_lat['y'],grid_lon['x']]\n",
    "#     #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "#     #db.columns=['lat','lon']\n",
    "#     #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     return idx\n",
    "\n",
    "\n",
    "# def polygon_point_kdtree(building_points,kdtree_building_points,x):\n",
    "#     '''\n",
    "#     Notes\n",
    "#     '''\n",
    "#     #idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "#     #pts_in_poly_roundbuffer=building_points[idx]\n",
    "#     #     if isinstance(row, pd.Series):\n",
    "#     #         idx='hi'\n",
    "#     #     else:\n",
    "#     #         idx='hey'\n",
    "#     idx=['x'+str(x)]\n",
    "#     #idx=[row['gn'],row['gn']]\n",
    "#     #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "#     #db.columns=['lat','lon']\n",
    "#     #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_db['bp_idx'] = grid_db[['y','x','geometry']].swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']))\n",
    "\n",
    "grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\n",
    "\n",
    "\n",
    "#data[['bikes_available', 'docks_available']].swifter.apply(lambda row: polygon_point_kdtree(building_points,kdtree_building_points,row['y'],row['x'],row['geometry']))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648589a",
   "metadata": {},
   "source": [
    "data[\"bikes_available_per_dock_available\"] = data[['bikes_available', 'docks_available']].swifter.apply(lambda row: bikes_per_dock_availability_ratio(row[\"bikes_available\"], row[\"docks_available\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc9910bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=kdt_bdpt_list.query_ball_point([30.004583333333336,4.994583333333334],r=0.007)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4138b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 ms, sys: 21 µs, total: 31.1 ms\n",
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "def bikes_proportion(x, max_x):\n",
    "    return x * 1.0 / max_x\n",
    "\n",
    "\n",
    "max_x = np.max(grid_db['x'])\n",
    "\n",
    "%time grid_db['test'] = grid_db['y'].swifter.apply(bikes_proportion, max_x=max_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3d60ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gn</th>\n",
       "      <th>Maille</th>\n",
       "      <th>Maille_Y</th>\n",
       "      <th>Maille_X</th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>test</th>\n",
       "      <th>bp_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>249501</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.99958, 30.00958 4.99958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.994583</td>\n",
       "      <td>0.142724</td>\n",
       "      <td>[4.994583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>249001</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.98958, 30.00958 4.98958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.984583</td>\n",
       "      <td>0.142439</td>\n",
       "      <td>[4.984583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>248501</td>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.97958, 30.00958 4.97958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.974583</td>\n",
       "      <td>0.142153</td>\n",
       "      <td>[4.974583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>248001</td>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.96958, 30.00958 4.96958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.964583</td>\n",
       "      <td>0.141867</td>\n",
       "      <td>[4.9645833333333345, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>247501</td>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.95958, 30.00958 4.95958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.954583</td>\n",
       "      <td>0.141581</td>\n",
       "      <td>[4.954583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249996</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.04958, 34.99958 0.04958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>[0.04458333333339581, 34.994583333333054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249997</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.03958, 34.99958 0.03958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>[0.0345833333333958, 34.994583333333054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249998</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.02958, 34.99958 0.02958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>[0.0245833333333958, 34.994583333333054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249999</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.01958, 34.99958 0.01958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>[0.014583333333395797, 34.99458333333306]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>250000</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.00958, 34.99958 0.00958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>[0.004583333333395798, 34.99458333333306]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gn  Maille  Maille_Y  Maille_X  \\\n",
       "0            1  249501       500         1   \n",
       "1            2  249001       499         1   \n",
       "2            3  248501       498         1   \n",
       "3            4  248001       497         1   \n",
       "4            5  247501       496         1   \n",
       "...        ...     ...       ...       ...   \n",
       "249995  249996    2500         5       500   \n",
       "249996  249997    2000         4       500   \n",
       "249997  249998    1500         3       500   \n",
       "249998  249999    1000         2       500   \n",
       "249999  250000     500         1       500   \n",
       "\n",
       "                                                 geometry          x  \\\n",
       "0       POLYGON ((29.99958 4.99958, 30.00958 4.99958, ...  30.004583   \n",
       "1       POLYGON ((29.99958 4.98958, 30.00958 4.98958, ...  30.004583   \n",
       "2       POLYGON ((29.99958 4.97958, 30.00958 4.97958, ...  30.004583   \n",
       "3       POLYGON ((29.99958 4.96958, 30.00958 4.96958, ...  30.004583   \n",
       "4       POLYGON ((29.99958 4.95958, 30.00958 4.95958, ...  30.004583   \n",
       "...                                                   ...        ...   \n",
       "249995  POLYGON ((34.98958 0.04958, 34.99958 0.04958, ...  34.994583   \n",
       "249996  POLYGON ((34.98958 0.03958, 34.99958 0.03958, ...  34.994583   \n",
       "249997  POLYGON ((34.98958 0.02958, 34.99958 0.02958, ...  34.994583   \n",
       "249998  POLYGON ((34.98958 0.01958, 34.99958 0.01958, ...  34.994583   \n",
       "249999  POLYGON ((34.98958 0.00958, 34.99958 0.00958, ...  34.994583   \n",
       "\n",
       "               y      test                                     bp_idx  \n",
       "0       4.994583  0.142724    [4.994583333333334, 30.004583333333336]  \n",
       "1       4.984583  0.142439    [4.984583333333334, 30.004583333333336]  \n",
       "2       4.974583  0.142153    [4.974583333333334, 30.004583333333336]  \n",
       "3       4.964583  0.141867   [4.9645833333333345, 30.004583333333336]  \n",
       "4       4.954583  0.141581    [4.954583333333334, 30.004583333333336]  \n",
       "...          ...       ...                                        ...  \n",
       "249995  0.044583  0.001274  [0.04458333333339581, 34.994583333333054]  \n",
       "249996  0.034583  0.000988   [0.0345833333333958, 34.994583333333054]  \n",
       "249997  0.024583  0.000702   [0.0245833333333958, 34.994583333333054]  \n",
       "249998  0.014583  0.000417  [0.014583333333395797, 34.99458333333306]  \n",
       "249999  0.004583  0.000131  [0.004583333333395798, 34.99458333333306]  \n",
       "\n",
       "[250000 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb83d2",
   "metadata": {},
   "source": [
    "## quick test case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41183c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "import geopandas as gp\n",
    "\n",
    "\n",
    "bd_pt=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz')\n",
    "\n",
    "bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc14a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=bd_pt[0:1000]\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')    \n",
    "\n",
    "\n",
    "grid_db['x']=grid_db.centroid.x\n",
    "grid_db['y']=grid_db.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5341051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138963    0.364583\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db1=grid_db[grid_db['Maille']==18278]\n",
    "grid_db1['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd4e69f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36710294, 32.77071094],\n",
       "       [ 0.36465799, 32.77089591],\n",
       "       [ 0.36949202, 32.77238478]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bdpt_list0=db['lat_long'].tolist()\n",
    "bdpt_list=np.array(bdpt_list0)\n",
    "kdt_bdpt_list = KDTree(bdpt_list)\n",
    "\n",
    "\n",
    "\n",
    "idx=kdt_bdpt_list.query_ball_point([0.364583,32.774583],r=0.007)\n",
    "pts_in_poly_roundbuffer=bdpt_list[idx]\n",
    "pts_in_poly_roundbuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe4aac",
   "metadata": {},
   "source": [
    "## simple test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6c53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "import geopandas as gp\n",
    "\n",
    "bd_pt=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e040_dem_17f_buildings.csv.gz')\n",
    "\n",
    "bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)\n",
    "\n",
    "#fe=len(bd_pt)/16\n",
    "#db=bd_pt[0:int(fe)]\n",
    "\n",
    "bdpt_list0=bd_pt['lat_long'].tolist()\n",
    "bdpt_list=np.array(bdpt_list0)\n",
    "kdt_bdpt_list = KDTree(bdpt_list)\n",
    "\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e040_dem.shp')    \n",
    "\n",
    "\n",
    "grid_db['x']=grid_db.centroid.x\n",
    "grid_db['y']=grid_db.centroid.y\n",
    "\n",
    "# def polygon_point_kdtree(bd_pt,building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "#     '''\n",
    "#     Notes\n",
    "#     '''\n",
    "#     idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.07)\n",
    "#     pts_in_poly_roundbuffer=building_points[idx]\n",
    "#     #idx=[grid_lat,grid_lon]\n",
    "#     #bd_pt1=bd_pt.iloc[idx]\n",
    "#     db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "#     db.columns=['lat','lon']\n",
    "#     db['idx']=idx\n",
    "#     #gdf=gp.GeoDataFrame(bd_pt1,geometry=gp.points_from_xy(bd_pt1.longitude,bd_pt1.latitude))\n",
    "#     gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     poly_db=pd.DataFrame([grid_poly])\n",
    "#     poly_db.columns=['geometry']\n",
    "#     poly_db['poly_sn']=1\n",
    "#     gpoly_db=gp.GeoDataFrame(poly_db)\n",
    "#     pp_db=gp.sjoin(gpoly_db,gdf,how='right')\n",
    "#     pp_db1=pp_db[pp_db['poly_sn'].notnull()]\n",
    "#     pp_db_idx=len(pp_db1['idx'].tolist())\n",
    "#     return pp_db_idx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f4802e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01062321662902832,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 56,
       "postfix": null,
       "prefix": "Dask Apply",
       "rate": null,
       "total": 16,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7142b345bfdb459a9072c079423329e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/climada_env/lib/python3.8/site-packages/geopandas/geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "#     pts_in_poly_roundbuffer=building_points[idx]\n",
    "#     #idx=[grid_lat,grid_lon]\n",
    "#     #bd_pt1=bd_pt.iloc[idx]\n",
    "#     db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "#     db.columns=['lat','lon']\n",
    "#     db['idx']=idx\n",
    "#     #gdf=gp.GeoDataFrame(bd_pt1,geometry=gp.points_from_xy(bd_pt1.longitude,bd_pt1.latitude))\n",
    "#     gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     poly_db=pd.DataFrame([grid_poly])\n",
    "#     poly_db.columns=['geometry']\n",
    "#     poly_db['poly_sn']=1\n",
    "#     gpoly_db=gp.GeoDataFrame(poly_db)\n",
    "#     pp_db=gp.sjoin(gpoly_db,gdf,how='right')\n",
    "#     pp_db1=pp_db[pp_db['poly_sn'].notnull()]\n",
    "#     pp_db_idx=len(pp_db1['idx'].tolist())\n",
    "    return len(idx)\n",
    "\n",
    "\n",
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "    pts_in_poly_roundbuffer=building_points[idx]\n",
    "    bdb=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    bdb.columns=['lat','lon']\n",
    "    bdb['idx']=idx\n",
    "    min_long,min_lat,max_long,max_lat=grid_poly.bounds\n",
    "    bdb1=bdb.loc[(bdb['lon'] >=min_long ) & (bdb['lon'] <= max_long)]\n",
    "    bdb2=bdb1.loc[(bdb1['lat'] >=min_lat ) & (bdb1['lat'] <= max_lat)]\n",
    "    new_idx=bdb2['idx'].tolist()\n",
    "    bdb,bdb1,bdb2=[],[],[]\n",
    "#     db['idx']=idx\n",
    "#     #gdf=gp.GeoDataFrame(bd_pt1,geometry=gp.points_from_xy(bd_pt1.longitude,bd_pt1.latitude))\n",
    "#     gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     poly_db=pd.DataFrame([grid_poly])\n",
    "#     poly_db.columns=['geometry']\n",
    "#     poly_db['poly_sn']=1\n",
    "#     gpoly_db=gp.GeoDataFrame(poly_db)\n",
    "#     pp_db=gp.sjoin(gpoly_db,gdf,how='right')\n",
    "#     pp_db1=pp_db[pp_db['poly_sn'].notnull()]\n",
    "#     pp_db_idx=len(pp_db1['idx'].tolist())\n",
    "    return new_idx\n",
    "\n",
    "\n",
    "#grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\n",
    "\n",
    "#grid_db['bp_circle_idx'] = grid_db.swifter.set_dask_scheduler('processes').set_npartitions(16).apply(lambda row: polygon_point_kdtree(bd_pt,bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\n",
    "#250000\n",
    "grid_db1=grid_db[0:250000]\n",
    "\n",
    "grid_db1['bp_circle_idx'] = grid_db1.swifter.set_dask_scheduler('processes').set_npartitions(16).apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1804a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the run time\n",
    "#50000-24\n",
    "#150000-72\n",
    "#250000-111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1d95d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/climada_env/lib/python3.8/site-packages/geopandas/geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "grid_db1['length'] = grid_db1['bp_circle_idx'].str.len()\n",
    "#db=grid_db1.iloc[grid_db1['length'].max()]\n",
    "#db\n",
    "#grid_db1['length'].max()\n",
    "#db\n",
    "db=grid_db1[grid_db1['length']==8255]\n",
    "db_list=db['bp_circle_idx'].tolist()\n",
    "bd_pt1=bd_pt.iloc[db_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "661b371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_546/1409244820.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bd_pt1.drop(columns=['lat_long'], inplace=True)\n",
      "/tmp/ipykernel_546/1409244820.py:4: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file('/home/data_folder/points_s2_level_4_gzip/km_intersection/test2.shp')\n"
     ]
    }
   ],
   "source": [
    "#bd_pt1\n",
    "bd_pt1.drop(columns=['lat_long'], inplace=True)\n",
    "gdf=gp.GeoDataFrame(bd_pt1,geometry=gp.points_from_xy(bd_pt1.longitude,bd_pt1.latitude))\n",
    "gdf.to_file('/home/data_folder/points_s2_level_4_gzip/km_intersection/test2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7df7008b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gn</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>bp_circle_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40.004583</td>\n",
       "      <td>4.994583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40.004583</td>\n",
       "      <td>4.984583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40.004583</td>\n",
       "      <td>4.974583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40.004583</td>\n",
       "      <td>4.964583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40.004583</td>\n",
       "      <td>4.954583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249996</td>\n",
       "      <td>44.994583</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249997</td>\n",
       "      <td>44.994583</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249998</td>\n",
       "      <td>44.994583</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249999</td>\n",
       "      <td>44.994583</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>250000</td>\n",
       "      <td>44.994583</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067355 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gn          x         y bp_circle_idx\n",
       "0            1  40.004583  4.994583           NaN\n",
       "1            2  40.004583  4.984583           NaN\n",
       "2            3  40.004583  4.974583           NaN\n",
       "3            4  40.004583  4.964583           NaN\n",
       "4            5  40.004583  4.954583           NaN\n",
       "...        ...        ...       ...           ...\n",
       "249995  249996  44.994583  0.044583           NaN\n",
       "249996  249997  44.994583  0.034583           NaN\n",
       "249997  249998  44.994583  0.024583           NaN\n",
       "249998  249999  44.994583  0.014583           NaN\n",
       "249999  250000  44.994583  0.004583           NaN\n",
       "\n",
       "[1067355 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db2=grid_db1.explode('bp_circle_idx')\n",
    "grid_db2.drop(columns=['Maille','Maille_Y','Maille_X','geometry','Length','length'], inplace=True)\n",
    "grid_db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79aceef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 250000 entries, 0 to 249999\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   gn             250000 non-null  int64   \n",
      " 1   Maille         250000 non-null  int64   \n",
      " 2   Maille_Y       250000 non-null  int64   \n",
      " 3   Maille_X       250000 non-null  int64   \n",
      " 4   geometry       250000 non-null  geometry\n",
      " 5   x              250000 non-null  float64 \n",
      " 6   y              250000 non-null  float64 \n",
      " 7   bp_circle_idx  14824 non-null   object  \n",
      " 8   Length         250000 non-null  int64   \n",
      " 9   length         250000 non-null  int64   \n",
      "dtypes: float64(2), geometry(1), int64(6), object(1)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "db=grid_db2.drop_duplicates('Maille')\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19e7d637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>area_in_meters</th>\n",
       "      <th>confidence</th>\n",
       "      <th>full_plus_code</th>\n",
       "      <th>dem_name</th>\n",
       "      <th>lat_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.410209</td>\n",
       "      <td>40.593686</td>\n",
       "      <td>12.6243</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>6HJ2CH6V+3FM9</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(2.41020905, 40.59368613)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.747014</td>\n",
       "      <td>40.039337</td>\n",
       "      <td>125.5660</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>6HH2P2WQ+RP4H</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.74701438, 40.03933721)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196015</td>\n",
       "      <td>40.288442</td>\n",
       "      <td>67.7493</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>6HG257WQ+C94C</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(0.19601454, 40.28844246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.626595</td>\n",
       "      <td>40.006846</td>\n",
       "      <td>24.7835</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>6HH2J2G4+JPQR</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.6265953, 40.00684637)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.526525</td>\n",
       "      <td>40.971231</td>\n",
       "      <td>5.7109</td>\n",
       "      <td>0.6271</td>\n",
       "      <td>6HM2GXGC+JF93</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(3.52652511, 40.97123104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832343</th>\n",
       "      <td>3.136439</td>\n",
       "      <td>43.677793</td>\n",
       "      <td>59.7926</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>6HM54MPH+H4FF</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(3.13643851, 43.67779344)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832344</th>\n",
       "      <td>1.692214</td>\n",
       "      <td>44.498492</td>\n",
       "      <td>37.7684</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>6HH6MFRX+V9QG</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.69221435, 44.49849206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832345</th>\n",
       "      <td>2.621967</td>\n",
       "      <td>44.892878</td>\n",
       "      <td>15.4014</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>6HJ6JVCV+Q5JJ</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(2.62196692, 44.89287764)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832346</th>\n",
       "      <td>1.854906</td>\n",
       "      <td>44.748093</td>\n",
       "      <td>35.7378</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>6HH6VP3X+X689</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.85490561, 44.74809301)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832347</th>\n",
       "      <td>0.190143</td>\n",
       "      <td>40.277151</td>\n",
       "      <td>52.0774</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>6HG257RG+3V2Q</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(0.190143, 40.27715093)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832348 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude  area_in_meters  confidence full_plus_code  \\\n",
       "0       2.410209  40.593686         12.6243      0.6390  6HJ2CH6V+3FM9   \n",
       "1       1.747014  40.039337        125.5660      0.8037  6HH2P2WQ+RP4H   \n",
       "2       0.196015  40.288442         67.7493      0.8116  6HG257WQ+C94C   \n",
       "3       1.626595  40.006846         24.7835      0.7403  6HH2J2G4+JPQR   \n",
       "4       3.526525  40.971231          5.7109      0.6271  6HM2GXGC+JF93   \n",
       "...          ...        ...             ...         ...            ...   \n",
       "832343  3.136439  43.677793         59.7926      0.8398  6HM54MPH+H4FF   \n",
       "832344  1.692214  44.498492         37.7684      0.7276  6HH6MFRX+V9QG   \n",
       "832345  2.621967  44.892878         15.4014      0.7551  6HJ6JVCV+Q5JJ   \n",
       "832346  1.854906  44.748093         35.7378      0.7463  6HH6VP3X+X689   \n",
       "832347  0.190143  40.277151         52.0774      0.8283  6HG257RG+3V2Q   \n",
       "\n",
       "           dem_name                   lat_long  \n",
       "0       n00e040_dem  (2.41020905, 40.59368613)  \n",
       "1       n00e040_dem  (1.74701438, 40.03933721)  \n",
       "2       n00e040_dem  (0.19601454, 40.28844246)  \n",
       "3       n00e040_dem   (1.6265953, 40.00684637)  \n",
       "4       n00e040_dem  (3.52652511, 40.97123104)  \n",
       "...             ...                        ...  \n",
       "832343  n00e040_dem  (3.13643851, 43.67779344)  \n",
       "832344  n00e040_dem  (1.69221435, 44.49849206)  \n",
       "832345  n00e040_dem  (2.62196692, 44.89287764)  \n",
       "832346  n00e040_dem  (1.85490561, 44.74809301)  \n",
       "832347  n00e040_dem    (0.190143, 40.27715093)  \n",
       "\n",
       "[832348 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https://github.com/jmcarpenter2/swifter/issues/45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ad72ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>poly_sn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((39.99958 4.99958, 40.00958 4.99958, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  poly_sn\n",
       "0  POLYGON ((39.99958 4.99958, 40.00958 4.99958, ...        1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db1=grid_db.iloc[0:1]\n",
    "db=pd.DataFrame(grid_db1['geometry'].values)\n",
    "db.columns=['geometry']\n",
    "db['poly_sn']=1\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a40e7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bd_pt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbd_pt\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bd_pt' is not defined"
     ]
    }
   ],
   "source": [
    "bd_pt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c67149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 832348 entries, 0 to 832347\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   latitude        832348 non-null  float64\n",
      " 1   longitude       832348 non-null  float64\n",
      " 2   area_in_meters  832348 non-null  float64\n",
      " 3   confidence      832348 non-null  float64\n",
      " 4   full_plus_code  832348 non-null  object \n",
      " 5   dem_name        832348 non-null  object \n",
      " 6   lat_long        832348 non-null  object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 44.5+ MB\n"
     ]
    }
   ],
   "source": [
    "bd_pt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af1bac",
   "metadata": {},
   "source": [
    "## making the CSV.GZ files the size of 20MB to use it with grid intersection without issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "779a1016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31 entries, 2 to 108\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   path     31 non-null     object \n",
      " 1   size_mb  31 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 744.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "gzfiles=glob.glob('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/*.csv.gz')\n",
    "\n",
    "\n",
    "\n",
    "def get_size(path):\n",
    "    size = os.path.getsize(path)\n",
    "    if size < 1024:\n",
    "        return f\"{size} bytes\"\n",
    "    elif size < pow(1024,2):\n",
    "        return f\"{round(size/1024, 2)} KB\"\n",
    "    elif size < pow(1024,3):\n",
    "        return f\"{round(size/(pow(1024,2)), 2)} MB\"\n",
    "    elif size < pow(1024,4):\n",
    "        return f\"{round(size/(pow(1024,3)), 2)} GB\"\n",
    "    \n",
    "    \n",
    "def get_size_mb(path):\n",
    "    size = os.path.getsize(path)\n",
    "    return round(size/(pow(1024,2)), 2)\n",
    "    \n",
    "    \n",
    "db=pd.DataFrame(gzfiles)\n",
    "db.columns=['path']\n",
    "\n",
    "db['size_mb']=db.apply(lambda row: get_size_mb(row['path']),axis=1 )\n",
    "db1=db[db['size_mb']>=20]\n",
    "db1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a852e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_546/2903526033.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  db1['filename']=db1.apply(lambda row: ntpath.basename(row['path']),axis=1)\n"
     ]
    }
   ],
   "source": [
    "import ntpath\n",
    "\n",
    "db1['filename']=db1.apply(lambda row: ntpath.basename(row['path']),axis=1)\n",
    "\n",
    "size=800000\n",
    "\n",
    "for idx, row in db1.iterrows():\n",
    "    for i, chunk in enumerate(pd.read_csv(row['path'], chunksize=size)):\n",
    "        output_name=row['filename']\n",
    "        chunk.to_csv(f\"/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/size_chunk_20mb/part{i}_{output_name}\", compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "457e93f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n00e025_dem_171_buildings.csv.gz'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntpath.basename(gzfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57629855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read csv gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ntpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m bdpt_list\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(bdpt_list0)\n\u001b[1;32m     53\u001b[0m kdt_bdpt_list \u001b[38;5;241m=\u001b[39m KDTree(bdpt_list)\n\u001b[0;32m---> 54\u001b[0m output_name\u001b[38;5;241m=\u001b[39m\u001b[43mntpath\u001b[49m\u001b[38;5;241m.\u001b[39mbasename(flcsvgz)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m km_sapefiles_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ntpath' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "import geopandas as gp\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "\n",
    "files_csvgz=glob.glob('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/size_chunk_20mb/*.csv.gz')\n",
    "\n",
    "\n",
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Based on following notes to optimize the point in polygon compute\n",
    "    https://stackoverflow.com/questions/27523982/how-to-find-set-of-points-in-x-y-grid-using-kdtree-query-ball-tree\n",
    "    https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "    \n",
    "    The query_ball_point returns list index of points, buffered of a circle, so 0.01, the radius is choosen 0.007\n",
    "    to have circle covering the 0.01 square grid. Following the kdtree operation. The points are further subset\n",
    "    to fill the 0.01 square grid. \n",
    "    #the run time\n",
    "    #50000-24\n",
    "    #150000-72\n",
    "    #250000-111\n",
    "    The input points count from csv.gz are clipped into 0.8 million as it wored for 1km 0.25 million grids\n",
    "    within 111. So all the csv.gz files are chunked into 20MB size 0.8 million points.\n",
    "    \n",
    "    The pandas apply using swifter was enabled with dask to avoid crash\n",
    "    https://github.com/jmcarpenter2/swifter/issues/45\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "    pts_in_poly_roundbuffer=building_points[idx]\n",
    "    bdb=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    bdb.columns=['lat','lon']\n",
    "    bdb['idx']=idx\n",
    "    min_long,min_lat,max_long,max_lat=grid_poly.bounds\n",
    "    bdb1=bdb.loc[(bdb['lon'] >=min_long ) & (bdb['lon'] <= max_long)]\n",
    "    bdb2=bdb1.loc[(bdb1['lat'] >=min_lat ) & (bdb1['lat'] <= max_lat)]\n",
    "    new_idx=bdb2['idx'].tolist()\n",
    "    bdb,bdb1,bdb2=[],[],[]\n",
    "    return new_idx\n",
    "\n",
    "#for idx,flcsvgz in enumerate(files_csvgz):\n",
    "for idx,flcsvgz in enumerate(files_csvgz[23:]):\n",
    "    bd_pt=pd.read_csv(flcsvgz)\n",
    "    bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)\n",
    "    #fe=len(bd_pt)/16\n",
    "    #db=bd_pt[0:int(fe)]\n",
    "    print('read csv gz')\n",
    "    bdpt_list0=bd_pt['lat_long'].tolist()\n",
    "    bdpt_list=np.array(bdpt_list0)\n",
    "    kdt_bdpt_list = KDTree(bdpt_list)\n",
    "    output_name=ntpath.basename(flcsvgz)\n",
    "    print(f'started {output_name}')\n",
    "    km_sapefiles_name='_'.join(output_name.split('_')[1:3])\n",
    "    grid_db=gp.read_file(f'/home/data_folder/osm_data/5x5_1km_grids_ea/{km_sapefiles_name}.shp')    \n",
    "    print('read 1km grid file')\n",
    "    grid_db['x']=grid_db.centroid.x\n",
    "    grid_db['y']=grid_db.centroid.y\n",
    "    grid_db['bp_circle_idx'] = grid_db.swifter.set_dask_scheduler('processes').set_npartitions(16).apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\n",
    "    grid_db1=grid_db.explode('bp_circle_idx')\n",
    "    grid_db1.drop(columns=['Maille','Maille_Y','Maille_X','geometry'], inplace=True)\n",
    "    grid_db1.to_csv(f'/home/data_folder/points_s2_level_4_gzip/km_intersection/{output_name}',compression='gzip',index=False)\n",
    "    del [[bd_pt,bdpt_list0,bdpt_list,kdt_bdpt_list,grid_db,grid_db1]]\n",
    "    gc.collect()\n",
    "    grid_db=pd.DataFrame()\n",
    "    grid_db1=pd.DataFrame()\n",
    "    bd_pt=pd.DataFrame()\n",
    "    print(f'completed {output_name},{idx}/{len(files_csvgz)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4a54d1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'spli'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpart0_n10e035_dem_165_buildings.csv.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspli\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'spli'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7771de8e",
   "metadata": {},
   "source": [
    "## using iCPAC cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6359690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
