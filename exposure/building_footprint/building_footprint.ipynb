{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to download files for east africa\n",
    "\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/10d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/113_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/141_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/143_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/15d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/161_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/163_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/165_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/167_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/169_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/16b_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/16d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/16f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/171_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/173_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/175_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/177_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/179_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/17b_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/17d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/17f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/181_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/183_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/185_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/189_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/18f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/191_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/199_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/19b_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/19d_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/19f_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3d5_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3d7_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3d9_buildings.csv.gz .\n",
    "gsutil cp -R gs://open-buildings-data/v2/points_s2_level_4_gzip/3db_buildings.csv.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/ea_5x5_grid.shp')\n",
    "\n",
    "bdb=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/3d5_buildings.csv.gz')\n",
    "\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n",
    "db = gbdb.sjoin(grid_db, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import gc\n",
    "import dask_geopandas\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "gzfiles=glob.glob('/home/data_folder/points_s2_level_4_gzip/*.csv.gz')\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/ea_5x5_grid.shp')\n",
    "\n",
    "# for gzfl in gzfiles:\n",
    "#     print(gzfl)\n",
    "#     bdb=pd.read_csv(gzfl)\n",
    "#     gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "#     dgdf = dask_geopandas.from_geopandas(gbdb, npartitions=4)\n",
    "#     db = dgdf.sjoin(grid_db, how=\"left\")\n",
    "#     db.drop(columns=['geometry', 'index_right','sno'], inplace=True)\n",
    "#     db.fillna('out_of_ea', inplace=True)\n",
    "#     dem_db=db.drop_duplicates('dem_name')\n",
    "#     dem_name_list=dem_db['dem_name'].tolist()\n",
    "#     dem_name_list=[i for i in dem_name_list if not i in 'out_of_ea']\n",
    "#     outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "#     del [[bdb,gbdb,dem_db]]\n",
    "#     gc.collect()\n",
    "#     bdb=pd.DataFrame()\n",
    "#     gbdb=pd.DataFrame()\n",
    "#     dem_db=pd.DataFrame()\n",
    "#     for dem_name in dem_name_list:\n",
    "#         db1=db[db['dem_name']==dem_name]\n",
    "#         db1.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter/{dem_name}_{outputname}.csv.gz', compression='gzip')\n",
    "#         del [[db1]]\n",
    "#         gc.collect()\n",
    "#         db1=pd.DataFrame()\n",
    "\n",
    "\n",
    "# for gzfl in gzfiles[8:]:\n",
    "#     print(gzfl)\n",
    "#     #bdb=pd.read_csv(gzfl)\n",
    "#     do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "#     bdb=do_dask_compute0.compute()\n",
    "#     gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "#     dgdf = dask_geopandas.from_geopandas(gbdb, npartitions=4)\n",
    "#     do_dask_compute = dgdf.sjoin(grid_db, how=\"inner\")\n",
    "#     db = do_dask_compute.compute()\n",
    "#     print(db.info())\n",
    "#     if db.empty:\n",
    "#         pass\n",
    "#     else:\n",
    "#         db.drop(columns=['geometry', 'index_right','sno'], inplace=True)\n",
    "#         dem_db=db.drop_duplicates('dem_name')\n",
    "#         print(dem_db)\n",
    "#         dem_name_list=dem_db['dem_name'].tolist()\n",
    "#         outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "#         del [[bdb,gbdb,dem_db]]\n",
    "#         gc.collect()\n",
    "#         bdb=pd.DataFrame()\n",
    "#         gbdb=pd.DataFrame()\n",
    "#         dem_db=pd.DataFrame()\n",
    "#         print('###########')\n",
    "#         for dem_name in dem_name_list:\n",
    "#             print(dem_name)\n",
    "#             print(db.info())\n",
    "#             db1=db[db['dem_name']==dem_name]\n",
    "#             db1.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter/{dem_name}_{outputname}.csv.gz', compression='gzip')\n",
    "#     del [[db1,db]]\n",
    "#     gc.collect()\n",
    "#     db1=pd.DataFrame()\n",
    "#     db=pd.DataFrame()\n",
    "\n",
    "\n",
    "# for gzfl in gzfiles:\n",
    "#     print(gzfl)\n",
    "#     #bdb=pd.read_csv(gzfl)\n",
    "#     do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "#     bdb=do_dask_compute0.compute()\n",
    "#     outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "#     for idx, row in grid_db.iterrows():\n",
    "#         min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "#         bdb = bdb.query(f'{min_long} < longitude < {max_long}')\n",
    "#         bdb = bdb.query(f'{min_lat} < latitude < {max_lat}')\n",
    "#         if not bdb.empty:\n",
    "#             print(bdb.info())\n",
    "#             bdb['dem_name']=row['dem_name']\n",
    "#             dem_name=row['dem_name']\n",
    "#             bdb.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter/{dem_name}_{outputname}.csv.gz', compression='gzip',index=False)\n",
    "#     gc.collect()\n",
    "#     del [[bdb]]\n",
    "#     bdb=pd.DataFrame()\n",
    "\n",
    "\n",
    "for gzfl in gzfiles:\n",
    "    print(gzfl)\n",
    "    #bdb=pd.read_csv(gzfl)\n",
    "    do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "    bdb=do_dask_compute0.compute()\n",
    "    outputname=ntpath.basename(gzfl).split('.')[0]\n",
    "    for idx, row in grid_db.iterrows():\n",
    "        min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "        bdb1=bdb.loc[(bdb['longitude'] >=min_long ) & (bdb['longitude'] <= max_long)]\n",
    "        bdb2=bdb1.loc[(bdb1['latitude'] >=min_lat ) & (bdb1['latitude'] <= max_lat)]\n",
    "        if not bdb2.empty:\n",
    "            print(bdb2.info())\n",
    "            bdb2['dem_name']=row['dem_name']\n",
    "            dem_name=row['dem_name']\n",
    "            bdb2.to_csv(f'/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/{dem_name}_{outputname}.csv.gz', compression='gzip',index=False)\n",
    "            del [[bdb1,bdb2]]\n",
    "    gc.collect()\n",
    "    del [[bdb]]\n",
    "    bdb=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae79652",
   "metadata": {},
   "source": [
    "## replicate rtree method for building points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792a817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5446d516",
   "metadata": {},
   "source": [
    "## do 1km intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import geopandas as gp\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd081a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')\n",
    "# dgdf = dask_geopandas.from_geopandas(gbdb, npartitions=4)\n",
    "# do_dask_compute = dgdf.sjoin(grid_db, how=\"inner\")\n",
    "# db = do_dask_compute.compute()\n",
    "\n",
    "sindex = gbdb.sindex\n",
    "# possible_matches_index = list(sindex.intersection(geometry.bounds))\n",
    "# possible_matches = gdf_nodes.iloc[possible_matches_index]\n",
    "# precise_matches = possible_matches[possible_matches.intersects(geometry)]\n",
    "\n",
    "points_within_geometry = pd.DataFrame()\n",
    "\n",
    "for idx,row in grid_db.iterrows():\n",
    "    # buffer by the <1 micron dist to account for any space lost in the quadrat cutting\n",
    "    # otherwise may miss point(s) that lay directly on quadrat line\n",
    "    poly = row['geometry'].buffer(1e-14).buffer(0)\n",
    "\n",
    "    # find approximate matches with r-tree, then precise matches from those approximate ones\n",
    "    possible_matches_index = list(sindex.intersection(poly.bounds))\n",
    "    possible_matches = gbdb.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.intersects(poly)]\n",
    "    points_within_geometry = points_within_geometry.append(precise_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210463e3",
   "metadata": {},
   "source": [
    "## Following the road network inteserction method for point as well\n",
    "1. For OSM road network it took 10 hours for all the 5x5 grid\n",
    "2. expecting similar operation for building points as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf55f6c",
   "metadata": {},
   "source": [
    "## test routine \n",
    "1. the csv.gz file has to be converted into shape file first \n",
    "2. then do the usual operation of point in polygon following road network intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import geopandas as gp\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e045_dem_3d5_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n",
    "#gbdb.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/n00e030_dem_177_buildings.shp',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10991b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdb=[]\n",
    "gbdb.drop(columns=['latitude', 'longitude','area_in_meters','confidence','full_plus_code','dem_name'], inplace=True)\n",
    "gbdb.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/n00e045_dem_3d5_buildings.shp',index=False)\n",
    "#gbdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "millnames = ['',' Thousand',' Million',' Billion',' Trillion']\n",
    "\n",
    "def millify(n):\n",
    "    n = float(n)\n",
    "    millidx = max(0,min(len(millnames)-1,\n",
    "                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))\n",
    "    return '{:.0f}{}'.format(n / 10**(3 * millidx), millnames[millidx])\n",
    "\n",
    "millify(len(gbdb.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape, mapping\n",
    "import rtree\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import ntpath\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "def intersect(buidling_shp_layer,boundary_shp,grid_name,output_shp,dummy_schema):\n",
    "    with fiona.open(boundary_shp, 'r') as boundary_shp_layer:\n",
    "        # We copy schema and add the  new property for the new resulting shp\n",
    "        schema = dummy_schema\n",
    "        schema['properties']['gno'] = 'int:10'\n",
    "        schema['properties']['latitude'] = 'int:10'\n",
    "        schema['properties']['longitude'] = 'int:10'\n",
    "        schema['properties']['area_in_meters'] = 'int:10'\n",
    "        schema['properties']['confidence'] = 'int:10'\n",
    "        schema['properties']['full_plus_code'] = 'str'\n",
    "        schema['properties']['dem_name'] = 'str'\n",
    "        # We open a first empty shp to write new content from both others shp\n",
    "        with fiona.open(output_shp, 'w', 'ESRI Shapefile', schema) as output_shp_layer:\n",
    "            index = rtree.index.Index()\n",
    "            for feat1 in boundary_shp_layer:\n",
    "                fid = int(feat1['id'])\n",
    "                geom1 = shape(feat1['geometry'])\n",
    "                index.insert(fid, geom1.bounds)\n",
    "            for feat2 in buidling_shp_layer:\n",
    "                geom2 = shape(feat2['geometry'])\n",
    "                for fid in list(index.intersection(geom2.bounds)):\n",
    "                    if fid != int(feat2['id']):\n",
    "                        feat1 = boundary_shp_layer[fid]\n",
    "                        geom1 = shape(feat1['geometry'])\n",
    "                        if geom1.intersects(geom2):\n",
    "                            # We take attributes from ctSHP\n",
    "                            props = feat2['properties']\n",
    "                            # Then append the uid attribute we want from the other shp\n",
    "                            #props['code'] = grid_name\n",
    "                            geom3=geom1.intersection(geom2)\n",
    "                            if geom3.geom_type=='GeometryCollection':\n",
    "                                print(\"empty geometry\")\n",
    "                            #elif geom3.geom_type=='Point':\n",
    "                            #    print(props)\n",
    "                            else:\n",
    "                                props['gno'] = feat1['properties']['Maille']\n",
    "                                output_shp_layer.write({\n",
    "                                  'properties': props,\n",
    "                                  'geometry': mapping(geom1.intersection(geom2))\n",
    "                                })\n",
    "\n",
    "buidling_shp_layer=pointpd   \n",
    "\n",
    "boundary_shp=f'/home/data_folder/osm_data/5x5_1km_grids_ea/n00e045_dem.shp'\n",
    "\n",
    "grid_name='km_intersection'\n",
    "\n",
    "output_shp='/home/data_folder/points_s2_level_4_gzip/km_intersection/test1.shp'\n",
    "intersect(buidling_shp_layer,boundary_shp,grid_name,output_shp,dummy_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_shp  = '/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/n00e045_dem_3d5_buildings.shp'\n",
    "road_shp_layer= fiona.open(road_shp, 'r')\n",
    "\n",
    "dummy_schema = road_shp_layer.schema.copy()\n",
    "\n",
    "dummy_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ef25f",
   "metadata": {},
   "source": [
    "## convert geopandsa into fiona collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8177ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import geopandas as gp\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e045_dem_3d5_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "gbdb = gp.GeoDataFrame(bdb, geometry=gp.points_from_xy(bdb.longitude, bdb.latitude))\n",
    "\n",
    "#dd=df.loc[:, df.columns != 'geometry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f323b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def extract_point_coords(index,row,rdd):\n",
    "    geom=row['geometry'].coords[:][0]\n",
    "    res = zip(row[rdd].index,row[rdd])\n",
    "    return {'geometry':{'coordinates': geom,'type': 'Point'},\n",
    "             'id':index,\n",
    "             'properties':OrderedDict(res),\n",
    "            'type': 'Feature'}\n",
    "  \n",
    "\n",
    "rdd=gbdb.columns\n",
    "  \n",
    "pointpd=[]\n",
    "for index, row in gbdb[0:1000].iterrows():\n",
    "    ee=extract_point_coords(index,row,rdd)\n",
    "    pointpd.append(ee)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6584fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom2 = shape(pointpd[0]['geometry'])\n",
    "pointpd[0]['geometry'],geom2.bounds\n",
    "#geom2.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=gp.read_file('/home/data_folder/points_s2_level_4_gzip/km_intersection/test.shp')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=gbdb[0:1000]\n",
    "aa.to_file('/home/data_folder/points_s2_level_4_gzip/km_intersection/points.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4880b1",
   "metadata": {},
   "source": [
    "## Using non gis filtering method for 1km grid as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2752c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')\n",
    "\n",
    "gzfl='/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz'\n",
    "\n",
    "do_dask_compute0 = dd.read_csv(gzfl, compression='gzip')\n",
    "bdb=do_dask_compute0.compute()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cont_bc=[]\n",
    "for idx, row in grid_db.iterrows():\n",
    "    min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "    bdb1=bdb.loc[(bdb['longitude'] >=min_long ) & (bdb['longitude'] <= max_long)]\n",
    "    bdb2=bdb1.loc[(bdb1['latitude'] >=min_lat ) & (bdb1['latitude'] <= max_lat)]\n",
    "    if not bdb2.empty:\n",
    "        build_count=len(bdb2.index)\n",
    "    else:\n",
    "        build_count=0\n",
    "    cont_bc.append(build_count)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b950e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inpoly import inpoly2\n",
    "import numpy as np\n",
    "    \n",
    "xmin, xmax, ymin, ymax = 0, 1, 0, 1\n",
    "x0, y0, x1, y1 = 0.5, 0.5, 0, 1\n",
    "\n",
    "#define any n-sided polygon\n",
    "p = np.array([[xmin, ymin],\n",
    "              [xmax, ymin],\n",
    "              [xmax, ymax],\n",
    "              [xmin, ymax],\n",
    "              [xmin, ymin]])\n",
    "\n",
    "#define some coords\n",
    "coords = np.array([[x0, y0],\n",
    "                   [x1, y1]])\n",
    "\n",
    "#get boolean mask for points if in or on polygon perimeter\n",
    "isin, ison = inpoly2(coords, p)\n",
    "\n",
    "https://stackoverflow.com/questions/36399381/whats-the-fastest-way-of-checking-if-a-point-is-inside-a-polygon-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1285b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## keranl getting killed if th following file is read in pandas, so using dask\n",
    "\n",
    "#import pandas as pd\n",
    "#db=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/165_buildings.csv.gz')\n",
    "\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('/home/data_folder/points_s2_level_4_gzip/165_buildings.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946812c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dgdf.sjoin(grid_db, how=\"inner\")\n",
    "db1 = db.compute()\n",
    "#db.drop(columns=['geometry', 'index_right','sno'])\n",
    "#db.fillna('out_of_ea')\n",
    "#dem_db=db.drop_duplicates('dem_name')\n",
    "#dem_name_list=dem_db['dem_name'].tolist()\n",
    "#dem_db\n",
    "db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = gbdb.sjoin(grid_db, how=\"left\")\n",
    "dba=db.dropna()\n",
    "dba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5332ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_name_list=['n05e020_dem','out_of_ea', 'n10e020_dem']\n",
    "\n",
    "[i for i in dem_name_list if not i in 'out_of_ea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c348ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_db=db.drop_duplicates('dem_name')\n",
    "dem_db.fillna('out_of_ea', inplace=True)\n",
    "dem_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for idx, row in grd_db.iterrows():\n",
    "    min_long,min_lat,max_long,max_lat=row['geometry'].bounds\n",
    "    for gzfl in gzfiles:\n",
    "        bdb=pd.read_csv(gzfl)\n",
    "        bdb1=bdb.loc[(bdb['latitude'] >=min_lat ) & (bdb['latitude'] <= max_lat)]\n",
    "# bdb.loc[(bdb['longitude'] >=min_lon ) & (bdb['longitude'] <= max_lon)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b9be3",
   "metadata": {},
   "source": [
    "## make all 1km grid into single shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/ea_5x5_grid.shp')\n",
    "\n",
    "\n",
    "db_cont=[]\n",
    "for idx,row in grid_db.iterrows():\n",
    "    grid_name=row['dem_name']\n",
    "    db=gp.read_file(f'/home/data_folder/osm_data/5x5_1km_grids_ea/{grid_name}.shp')\n",
    "    db_cont.append(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "db=pd.concat(db_cont)\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db1=gp.GeoDataFrame(db)\n",
    "db1.to_file('/home/data_folder/osm_data/ea_5x5_1km_grids.shp',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_long,min_lat,max_long,max_lat=grid_db['geometry'][0].bounds\n",
    "\n",
    "# bdb.loc[(bdb['latitude'] >=min_lat ) & (bdb['latitude'] <= max_lat)]\n",
    "# bdb.loc[(bdb['longitude'] >=min_lon ) & (bdb['longitude'] <= max_lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_long,min_lat,max_long,max_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b90da",
   "metadata": {},
   "source": [
    "# Using KDTRee method with apply method \n",
    "\n",
    "https://stackoverflow.com/questions/27523982/how-to-find-set-of-points-in-x-y-grid-using-kdtree-query-ball-tree\n",
    "\n",
    "https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "\n",
    "1. earlier methods are inefficient in completing the grid intersection\n",
    "2. so using kdtree and apply method for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43600e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [2 2]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "pts = np.array([(1, 1), (2, 1), (3, 1), (4, 1), (1, 2), (2, 2), (3, 2), (4, 2), (1, 3), (2, 3), (3, 3), (4, 3), (1, 4), (2, 4), (3, 4), (4, 4)])\n",
    "\n",
    "T = KDTree(pts)\n",
    "idx = T.query_ball_point([1,1],r=2)\n",
    "print(pts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcd1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "#gd_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')\n",
    "\n",
    "bd_pt=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz')\n",
    "\n",
    "bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499c2ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/3244142547.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bd_pt1.drop(columns=['lat_long'], inplace=True)\n",
      "/tmp/ipykernel_2584/3244142547.py:10: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gbd_pt.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/test.shp')\n"
     ]
    }
   ],
   "source": [
    "#bdpt_list=bd_pt['lat_long'].tolist()\n",
    "\n",
    "bd_pt1=bd_pt[0:1000]\n",
    "\n",
    "# \n",
    "\n",
    "bd_pt1.drop(columns=['lat_long'], inplace=True)\n",
    "gbd_pt=gp.GeoDataFrame(bd_pt1,geometry=gp.points_from_xy(bd_pt1.longitude,bd_pt1.latitude))\n",
    "\n",
    "#gbd_pt.to_file('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_shp/test.shp')\n",
    "#bd_pt1\n",
    "gbd_pt['lat_long']=gbd_pt[['latitude','longitude']].apply(tuple,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272088e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18 Million'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "millnames = ['',' Thousand',' Million',' Billion',' Trillion']\n",
    "\n",
    "def millify(n):\n",
    "    n = float(n)\n",
    "    millidx = max(0,min(len(millnames)-1,\n",
    "                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))\n",
    "    return '{:.0f}{}'.format(n / 10**(3 * millidx), millnames[millidx])\n",
    "\n",
    "millify(len(bd_pt.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd52a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "fe=len(bd_pt)/16\n",
    "db=bd_pt[0:int(fe)]\n",
    "\n",
    "bdpt_list0=db['lat_long'].tolist()\n",
    "bdpt_list=np.array(bdpt_list0)\n",
    "kdt_bdpt_list = KDTree(bdpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7388fabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1135259"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bdpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26666454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 Million'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millify(len(db.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee08b478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017192232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import objsize\n",
    "objsize.get_deep_size(bdpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4989f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "    pts_in_poly_roundbuffer=building_points[idx]\n",
    "    #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    #db.columns=['lat','lon']\n",
    "    #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "    return idx\n",
    "    \n",
    "\n",
    "    \n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')    \n",
    "\n",
    "\n",
    "grid_db['x']=grid_db.centroid.x\n",
    "grid_db['y']=grid_db.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "306061cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gn', 'Maille', 'Maille_Y', 'Maille_X', 'geometry', 'x', 'y'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce4f3828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169accb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "    #pts_in_poly_roundbuffer=building_points[idx]\n",
    "    #idx=[grid_lat,grid_lon]\n",
    "    #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    #db.columns=['lat','lon']\n",
    "    #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "    return idx\n",
    "\n",
    "\n",
    "# def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "#     '''\n",
    "#     Notes\n",
    "#     '''\n",
    "#     #idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "#     #pts_in_poly_roundbuffer=building_points[idx]\n",
    "#     idx=[grid_lat['y'],grid_lon['x']]\n",
    "#     #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "#     #db.columns=['lat','lon']\n",
    "#     #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     return idx\n",
    "\n",
    "\n",
    "# def polygon_point_kdtree(building_points,kdtree_building_points,x):\n",
    "#     '''\n",
    "#     Notes\n",
    "#     '''\n",
    "#     #idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.007)\n",
    "#     #pts_in_poly_roundbuffer=building_points[idx]\n",
    "#     #     if isinstance(row, pd.Series):\n",
    "#     #         idx='hi'\n",
    "#     #     else:\n",
    "#     #         idx='hey'\n",
    "#     idx=['x'+str(x)]\n",
    "#     #idx=[row['gn'],row['gn']]\n",
    "#     #db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "#     #db.columns=['lat','lon']\n",
    "#     #gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "#     return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a01f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_db['bp_idx'] = grid_db[['y','x','geometry']].swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']))\n",
    "\n",
    "grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\n",
    "\n",
    "\n",
    "#data[['bikes_available', 'docks_available']].swifter.apply(lambda row: polygon_point_kdtree(building_points,kdtree_building_points,row['y'],row['x'],row['geometry']))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2d7c1",
   "metadata": {},
   "source": [
    "data[\"bikes_available_per_dock_available\"] = data[['bikes_available', 'docks_available']].swifter.apply(lambda row: bikes_per_dock_availability_ratio(row[\"bikes_available\"], row[\"docks_available\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0aa6385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=kdt_bdpt_list.query_ball_point([30.004583333333336,4.994583333333334],r=0.007)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b17f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 ms, sys: 21 µs, total: 31.1 ms\n",
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "def bikes_proportion(x, max_x):\n",
    "    return x * 1.0 / max_x\n",
    "\n",
    "\n",
    "max_x = np.max(grid_db['x'])\n",
    "\n",
    "%time grid_db['test'] = grid_db['y'].swifter.apply(bikes_proportion, max_x=max_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "130b0986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gn</th>\n",
       "      <th>Maille</th>\n",
       "      <th>Maille_Y</th>\n",
       "      <th>Maille_X</th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>test</th>\n",
       "      <th>bp_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>249501</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.99958, 30.00958 4.99958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.994583</td>\n",
       "      <td>0.142724</td>\n",
       "      <td>[4.994583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>249001</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.98958, 30.00958 4.98958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.984583</td>\n",
       "      <td>0.142439</td>\n",
       "      <td>[4.984583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>248501</td>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.97958, 30.00958 4.97958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.974583</td>\n",
       "      <td>0.142153</td>\n",
       "      <td>[4.974583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>248001</td>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.96958, 30.00958 4.96958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.964583</td>\n",
       "      <td>0.141867</td>\n",
       "      <td>[4.9645833333333345, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>247501</td>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((29.99958 4.95958, 30.00958 4.95958, ...</td>\n",
       "      <td>30.004583</td>\n",
       "      <td>4.954583</td>\n",
       "      <td>0.141581</td>\n",
       "      <td>[4.954583333333334, 30.004583333333336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249996</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.04958, 34.99958 0.04958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>[0.04458333333339581, 34.994583333333054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249997</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.03958, 34.99958 0.03958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>[0.0345833333333958, 34.994583333333054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249998</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.02958, 34.99958 0.02958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>[0.0245833333333958, 34.994583333333054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249999</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.01958, 34.99958 0.01958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>[0.014583333333395797, 34.99458333333306]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>250000</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>POLYGON ((34.98958 0.00958, 34.99958 0.00958, ...</td>\n",
       "      <td>34.994583</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>[0.004583333333395798, 34.99458333333306]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gn  Maille  Maille_Y  Maille_X  \\\n",
       "0            1  249501       500         1   \n",
       "1            2  249001       499         1   \n",
       "2            3  248501       498         1   \n",
       "3            4  248001       497         1   \n",
       "4            5  247501       496         1   \n",
       "...        ...     ...       ...       ...   \n",
       "249995  249996    2500         5       500   \n",
       "249996  249997    2000         4       500   \n",
       "249997  249998    1500         3       500   \n",
       "249998  249999    1000         2       500   \n",
       "249999  250000     500         1       500   \n",
       "\n",
       "                                                 geometry          x  \\\n",
       "0       POLYGON ((29.99958 4.99958, 30.00958 4.99958, ...  30.004583   \n",
       "1       POLYGON ((29.99958 4.98958, 30.00958 4.98958, ...  30.004583   \n",
       "2       POLYGON ((29.99958 4.97958, 30.00958 4.97958, ...  30.004583   \n",
       "3       POLYGON ((29.99958 4.96958, 30.00958 4.96958, ...  30.004583   \n",
       "4       POLYGON ((29.99958 4.95958, 30.00958 4.95958, ...  30.004583   \n",
       "...                                                   ...        ...   \n",
       "249995  POLYGON ((34.98958 0.04958, 34.99958 0.04958, ...  34.994583   \n",
       "249996  POLYGON ((34.98958 0.03958, 34.99958 0.03958, ...  34.994583   \n",
       "249997  POLYGON ((34.98958 0.02958, 34.99958 0.02958, ...  34.994583   \n",
       "249998  POLYGON ((34.98958 0.01958, 34.99958 0.01958, ...  34.994583   \n",
       "249999  POLYGON ((34.98958 0.00958, 34.99958 0.00958, ...  34.994583   \n",
       "\n",
       "               y      test                                     bp_idx  \n",
       "0       4.994583  0.142724    [4.994583333333334, 30.004583333333336]  \n",
       "1       4.984583  0.142439    [4.984583333333334, 30.004583333333336]  \n",
       "2       4.974583  0.142153    [4.974583333333334, 30.004583333333336]  \n",
       "3       4.964583  0.141867   [4.9645833333333345, 30.004583333333336]  \n",
       "4       4.954583  0.141581    [4.954583333333334, 30.004583333333336]  \n",
       "...          ...       ...                                        ...  \n",
       "249995  0.044583  0.001274  [0.04458333333339581, 34.994583333333054]  \n",
       "249996  0.034583  0.000988   [0.0345833333333958, 34.994583333333054]  \n",
       "249997  0.024583  0.000702   [0.0245833333333958, 34.994583333333054]  \n",
       "249998  0.014583  0.000417  [0.014583333333395797, 34.99458333333306]  \n",
       "249999  0.004583  0.000131  [0.004583333333395798, 34.99458333333306]  \n",
       "\n",
       "[250000 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0150a9e",
   "metadata": {},
   "source": [
    "## quick test case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b3cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "import geopandas as gp\n",
    "\n",
    "\n",
    "bd_pt=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e030_dem_177_buildings.csv.gz')\n",
    "\n",
    "bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd562e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=bd_pt[0:1000]\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e030_dem.shp')    \n",
    "\n",
    "\n",
    "grid_db['x']=grid_db.centroid.x\n",
    "grid_db['y']=grid_db.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d891e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138963    0.364583\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db1=grid_db[grid_db['Maille']==18278]\n",
    "grid_db1['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55c2448a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36710294, 32.77071094],\n",
       "       [ 0.36465799, 32.77089591],\n",
       "       [ 0.36949202, 32.77238478]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bdpt_list0=db['lat_long'].tolist()\n",
    "bdpt_list=np.array(bdpt_list0)\n",
    "kdt_bdpt_list = KDTree(bdpt_list)\n",
    "\n",
    "\n",
    "\n",
    "idx=kdt_bdpt_list.query_ball_point([0.364583,32.774583],r=0.007)\n",
    "pts_in_poly_roundbuffer=bdpt_list[idx]\n",
    "pts_in_poly_roundbuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd35c8",
   "metadata": {},
   "source": [
    "## simple test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a87ee2f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/swifter/swifter.py:427\u001b[0m, in \u001b[0;36mDataFrameAccessor.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[0;32m--> 427\u001b[0m     tmp_df \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     sample_df \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mapply(func, axis\u001b[38;5;241m=\u001b[39maxis, raw\u001b[38;5;241m=\u001b[39mraw, result_type\u001b[38;5;241m=\u001b[39mresult_type, args\u001b[38;5;241m=\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "Cell \u001b[0;32mIn [19], line 47\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m grid_db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbp_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grid_db\u001b[38;5;241m.\u001b[39mswifter\u001b[38;5;241m.\u001b[39mset_dask_scheduler(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_npartitions(\u001b[38;5;241m16\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mpolygon_point_kdtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbdpt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkdt_bdpt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [19], line 29\u001b[0m, in \u001b[0;36mpolygon_point_kdtree\u001b[0;34m(building_points, kdtree_building_points, grid_lat, grid_lon, grid_poly)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mNotes\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m idx\u001b[38;5;241m=\u001b[39m\u001b[43mkdtree_building_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_ball_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrid_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrid_lon\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.07\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m pts_in_poly_roundbuffer\u001b[38;5;241m=\u001b[39mbuilding_points[idx]\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/scipy/spatial/_kdtree.py:536\u001b[0m, in \u001b[0;36mKDTree.query_ball_point\u001b[0;34m(self, x, r, p, eps, workers, return_sorted, return_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKDTree does not work with complex data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_ball_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_ckdtree.pyx:935\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.cKDTree.query_ball_point\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_ckdtree.pyx:1614\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.num_points\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x must consist of vectors of length 2 but has shape (2, 1000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pp_db_idx\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m grid_db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbp_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswifter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_dask_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocesses\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_npartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolygon_point_kdtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbdpt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkdt_bdpt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/swifter/swifter.py:436\u001b[0m, in \u001b[0;36mDataFrameAccessor.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ERRORS_TO_HANDLE:  \u001b[38;5;66;03m# if can't vectorize, estimate time to pandas apply\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_apply(func, axis\u001b[38;5;241m=\u001b[39maxis, raw\u001b[38;5;241m=\u001b[39mraw, result_type\u001b[38;5;241m=\u001b[39mresult_type, args\u001b[38;5;241m=\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 436\u001b[0m     timed \u001b[38;5;241m=\u001b[39m \u001b[43mtimeit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_REPEATS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     sample_proc_est \u001b[38;5;241m=\u001b[39m timed \u001b[38;5;241m/\u001b[39m N_REPEATS\n\u001b[1;32m    438\u001b[0m     est_apply_duration \u001b[38;5;241m=\u001b[39m sample_proc_est \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SAMPLE_SIZE \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nrows\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/timeit.py:233\u001b[0m, in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeit\u001b[39m(stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, timer\u001b[38;5;241m=\u001b[39mdefault_timer,\n\u001b[1;32m    231\u001b[0m            number\u001b[38;5;241m=\u001b[39mdefault_number, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/timeit.py:177\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/swifter/swifter.py:339\u001b[0m, in \u001b[0;36mDataFrameAccessor._wrapped_apply.<locals>.wrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m():\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_SAMPLE_INDEX\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/geopandas/geodataframe.py:1511\u001b[0m, in \u001b[0;36mGeoDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;129m@doc\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1511\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;66;03m# Reconstruct gdf if it was lost by apply\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1516\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(result, DataFrame)\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geometry_column_name \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1518\u001b[0m     ):\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;66;03m# axis=1 apply will split GeometryDType to object, try and cast back\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/frame.py:8848\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8837\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8839\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   8840\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8841\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8846\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   8847\u001b[0m )\n\u001b[0;32m-> 8848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/apply.py:733\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/apply.py:857\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 857\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    875\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    876\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    877\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [19], line 47\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pp_db_idx\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m grid_db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbp_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grid_db\u001b[38;5;241m.\u001b[39mswifter\u001b[38;5;241m.\u001b[39mset_dask_scheduler(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_npartitions(\u001b[38;5;241m16\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mpolygon_point_kdtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbdpt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkdt_bdpt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [19], line 41\u001b[0m, in \u001b[0;36mpolygon_point_kdtree\u001b[0;34m(building_points, kdtree_building_points, grid_lat, grid_lon, grid_poly)\u001b[0m\n\u001b[1;32m     39\u001b[0m pp_db\u001b[38;5;241m=\u001b[39mgp\u001b[38;5;241m.\u001b[39msjoin(gpoly_db,gdf,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m pp_db1\u001b[38;5;241m=\u001b[39mpp_db[pp_db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly_sn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m---> 41\u001b[0m pp_db_idx\u001b[38;5;241m=\u001b[39m\u001b[43mpp_db1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pp_db_idx\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/geopandas/geodataframe.py:1428\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;124;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;124;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;124;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     geo_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geometry_column_name\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result\u001b[38;5;241m.\u001b[39mdtype, GeometryDtype):\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/climada_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.spatial import KDTree\n",
    "import geopandas as gp\n",
    "\n",
    "bd_pt=pd.read_csv('/home/data_folder/points_s2_level_4_gzip/ea_grid_filter_t2/n00e040_dem_17f_buildings.csv.gz')\n",
    "\n",
    "bd_pt['lat_long']=bd_pt[['latitude','longitude']].apply(tuple,axis=1)\n",
    "\n",
    "#fe=len(bd_pt)/16\n",
    "#db=bd_pt[0:int(fe)]\n",
    "\n",
    "bdpt_list0=bd_pt['lat_long'].tolist()\n",
    "bdpt_list=np.array(bdpt_list0)\n",
    "kdt_bdpt_list = KDTree(bdpt_list)\n",
    "\n",
    "\n",
    "grid_db=gp.read_file('/home/data_folder/osm_data/5x5_1km_grids_ea/n00e040_dem.shp')    \n",
    "\n",
    "\n",
    "grid_db['x']=grid_db.centroid.x\n",
    "grid_db['y']=grid_db.centroid.y\n",
    "\n",
    "def polygon_point_kdtree(building_points,kdtree_building_points,grid_lat,grid_lon,grid_poly):\n",
    "    '''\n",
    "    Notes\n",
    "    '''\n",
    "    idx=kdtree_building_points.query_ball_point([grid_lat,grid_lon],r=0.07)\n",
    "    pts_in_poly_roundbuffer=building_points[idx]\n",
    "    #idx=[grid_lat,grid_lon]\n",
    "    db=pd.DataFrame(pts_in_poly_roundbuffer)\n",
    "    db.columns=['lat','lon']\n",
    "    gdf=gp.GeoDataFrame(db,geometry=gp.points_from_xy(db.lon,db.lat))\n",
    "    poly_db=pd.DataFrame([grid_poly])\n",
    "    poly_db.columns=['geometry']\n",
    "    poly_db['poly_sn']=1\n",
    "    gpoly_db=gp.GeoDataFrame(poly_db)\n",
    "    pp_db=gp.sjoin(gpoly_db,gdf,how='right')\n",
    "    pp_db1=pp_db[pp_db['poly_sn'].notnull()]\n",
    "    pp_db_idx=pp_db1['gn'].tolist()\n",
    "    return pp_db_idx\n",
    "\n",
    "\n",
    "#grid_db['bp_idx'] = grid_db.swifter.apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)\n",
    "\n",
    "grid_db['bp_idx'] = grid_db.swifter.set_dask_scheduler('processes').set_npartitions(16).apply(lambda row: polygon_point_kdtree(bdpt_list,kdt_bdpt_list,row['y'],row['x'],row['geometry']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b635600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>area_in_meters</th>\n",
       "      <th>confidence</th>\n",
       "      <th>full_plus_code</th>\n",
       "      <th>dem_name</th>\n",
       "      <th>lat_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.410209</td>\n",
       "      <td>40.593686</td>\n",
       "      <td>12.6243</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>6HJ2CH6V+3FM9</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(2.41020905, 40.59368613)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.747014</td>\n",
       "      <td>40.039337</td>\n",
       "      <td>125.5660</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>6HH2P2WQ+RP4H</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.74701438, 40.03933721)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196015</td>\n",
       "      <td>40.288442</td>\n",
       "      <td>67.7493</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>6HG257WQ+C94C</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(0.19601454, 40.28844246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.626595</td>\n",
       "      <td>40.006846</td>\n",
       "      <td>24.7835</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>6HH2J2G4+JPQR</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.6265953, 40.00684637)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.526525</td>\n",
       "      <td>40.971231</td>\n",
       "      <td>5.7109</td>\n",
       "      <td>0.6271</td>\n",
       "      <td>6HM2GXGC+JF93</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(3.52652511, 40.97123104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832343</th>\n",
       "      <td>3.136439</td>\n",
       "      <td>43.677793</td>\n",
       "      <td>59.7926</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>6HM54MPH+H4FF</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(3.13643851, 43.67779344)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832344</th>\n",
       "      <td>1.692214</td>\n",
       "      <td>44.498492</td>\n",
       "      <td>37.7684</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>6HH6MFRX+V9QG</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.69221435, 44.49849206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832345</th>\n",
       "      <td>2.621967</td>\n",
       "      <td>44.892878</td>\n",
       "      <td>15.4014</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>6HJ6JVCV+Q5JJ</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(2.62196692, 44.89287764)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832346</th>\n",
       "      <td>1.854906</td>\n",
       "      <td>44.748093</td>\n",
       "      <td>35.7378</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>6HH6VP3X+X689</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(1.85490561, 44.74809301)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832347</th>\n",
       "      <td>0.190143</td>\n",
       "      <td>40.277151</td>\n",
       "      <td>52.0774</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>6HG257RG+3V2Q</td>\n",
       "      <td>n00e040_dem</td>\n",
       "      <td>(0.190143, 40.27715093)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832348 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude  area_in_meters  confidence full_plus_code  \\\n",
       "0       2.410209  40.593686         12.6243      0.6390  6HJ2CH6V+3FM9   \n",
       "1       1.747014  40.039337        125.5660      0.8037  6HH2P2WQ+RP4H   \n",
       "2       0.196015  40.288442         67.7493      0.8116  6HG257WQ+C94C   \n",
       "3       1.626595  40.006846         24.7835      0.7403  6HH2J2G4+JPQR   \n",
       "4       3.526525  40.971231          5.7109      0.6271  6HM2GXGC+JF93   \n",
       "...          ...        ...             ...         ...            ...   \n",
       "832343  3.136439  43.677793         59.7926      0.8398  6HM54MPH+H4FF   \n",
       "832344  1.692214  44.498492         37.7684      0.7276  6HH6MFRX+V9QG   \n",
       "832345  2.621967  44.892878         15.4014      0.7551  6HJ6JVCV+Q5JJ   \n",
       "832346  1.854906  44.748093         35.7378      0.7463  6HH6VP3X+X689   \n",
       "832347  0.190143  40.277151         52.0774      0.8283  6HG257RG+3V2Q   \n",
       "\n",
       "           dem_name                   lat_long  \n",
       "0       n00e040_dem  (2.41020905, 40.59368613)  \n",
       "1       n00e040_dem  (1.74701438, 40.03933721)  \n",
       "2       n00e040_dem  (0.19601454, 40.28844246)  \n",
       "3       n00e040_dem   (1.6265953, 40.00684637)  \n",
       "4       n00e040_dem  (3.52652511, 40.97123104)  \n",
       "...             ...                        ...  \n",
       "832343  n00e040_dem  (3.13643851, 43.67779344)  \n",
       "832344  n00e040_dem  (1.69221435, 44.49849206)  \n",
       "832345  n00e040_dem  (2.62196692, 44.89287764)  \n",
       "832346  n00e040_dem  (1.85490561, 44.74809301)  \n",
       "832347  n00e040_dem    (0.190143, 40.27715093)  \n",
       "\n",
       "[832348 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "750a4454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>poly_sn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((39.99958 4.99958, 40.00958 4.99958, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  poly_sn\n",
       "0  POLYGON ((39.99958 4.99958, 40.00958 4.99958, ...        1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_db1=grid_db.iloc[0:1]\n",
    "db=pd.DataFrame(grid_db1['geometry'].values)\n",
    "db.columns=['geometry']\n",
    "db['poly_sn']=1\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52105bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
